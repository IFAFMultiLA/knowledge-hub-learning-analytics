
@article{Cooper1988,
  title={Organizing knowledge syntheses: A taxonomy of literature reviews},
  author={Harris Cooper},
  journal={Knowledge in Society},
  year={1988},
  volume={1},
  pages={104-126}
}

@article{herz2010,
author = {Herz, Thomas and Hamel, Florian and Uebernickel, Falk and Brenner, Walter},
year = {2010},
month = {01},
pages = {},
title = {Deriving a Research Agenda for the Management of Multisourcing Relationships Based on a Literature Review},
volume = {3},
journal = {http://www.alexandria.unisg.ch/Publikationen/69319}
}

@ARTICLE{matcha2020,
  author={Matcha, Wannisa and Uzir, Nora'ayu Ahmad and Gašević, Dragan and Pardo, Abelardo},
  journal={IEEE Transactions on Learning Technologies},
  title={A Systematic Review of Empirical Studies on Learning Analytics Dashboards: A Self-Regulated Learning Perspective},
  year={2020},
  volume={13},
  number={2},
  pages={226-245},
  doi={10.1109/TLT.2019.2916802}}

@misc{priem2022openalex,
      title={OpenAlex: A fully-open index of scholarly works, authors, venues, institutions, and concepts},
      author={Jason Priem and Heather Piwowar and Richard Orr},
      year={2022},
      eprint={2205.01833},
      archivePrefix={arXiv},
      primaryClass={cs.DL}
}

@article{martin2020,
title = {A systematic review of research on online teaching and learning from 2009 to 2018},
journal = {Computers & Education},
volume = {159},
pages = {104009},
year = {2020},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2020.104009},
url = {https://www.sciencedirect.com/science/article/pii/S0360131520302074},
author = {Florence Martin and Ting Sun and Carl D. Westine},
keywords = {Distance education, online teaching and learning, Systematic Review, Online Learning Research, Research Themes},
abstract = {Systematic reviews were conducted in the nineties and early 2000's on online learning research. However, there is no review examining the broader aspect of research themes in online learning in the last decade. This systematic review addresses this gap by examining 619 research articles on online learning published in twelve journals in the last decade. These studies were examined for publication trends and patterns, research themes, research methods, and research settings and compared with the research themes from the previous decades. While there has been a slight decrease in the number of studies on online learning in 2015 and 2016, it has then continued to increase in 2017 and 2018. The majority of the studies were quantitative in nature and were examined in higher education. Online learning research was categorized into twelve themes and a framework across learner, course and instructor, and organizational levels was developed. Online learner characteristics and online engagement were examined in a high number of studies and were consistent with three of the prior systematic reviews. However, there is still a need for more research on organization level topics such as leadership, policy, and management and access, culture, equity, inclusion, and ethics and also on online instructor characteristics.}
}

@article{hew2020,
author = {Hew, Khe and Jia, Chengyuan and Gonda, Donn and Bai, Shurui},
year = {2020},
month = {12},
pages = {},
title = {Transitioning to the "new normal" of learning in unpredictable times: pedagogical practices and learning performance in fully online flipped classrooms},
volume = {17},
journal = {International Journal of Educational Technology in Higher Education},
doi = {10.1186/s41239-020-00234-x}
}

@article{hu2008,
author = {Hu, Shouping and Kuh, George and Li, Shaoqing},
year = {2008},
month = {08},
pages = {71-81},
title = {The Effects of Engagement in Inquiry-Oriented Activities on Student Learning and Personal Development},
volume = {33},
journal = {Innovative Higher Education},
doi = {10.1007/s10755-008-9066-z}
}

@article{carini2006,
author = {Carini, Robert and Kuh, George and Klein, Stephen},
year = {2006},
month = {02},
pages = {1-32},
title = {Student Engagement and Student Learning: Testing the Linkages*},
volume = {47},
journal = {Research in Higher Education},
doi = {10.1007/s11162-005-8150-9}
}

@article{lewis2011,
author = {Lewis, Ashley and Huebner, E and Malone, Patrick and Valois, Robert},
year = {2010},
month = {03},
pages = {249-62},
title = {Life Satisfaction and Student Engagement in Adolescents},
volume = {40},
journal = {Journal of youth and adolescence},
doi = {10.1007/s10964-010-9517-6}
}

@Article{lee2019,
AUTHOR = {Lee, Jeongju and Song, Hae-Deok and Hong, Ah Jeong},
TITLE = {Exploring Factors, and Indicators for Measuring Students’ Sustainable Engagement in e-Learning},
JOURNAL = {Sustainability},
VOLUME = {11},
YEAR = {2019},
NUMBER = {4},
ARTICLE-NUMBER = {985},
URL = {https://www.mdpi.com/2071-1050/11/4/985},
ISSN = {2071-1050},
ABSTRACT = {The topic of engagement has been attracting increasing amounts of attention in the field of e-learning. Research shows that multifarious benefits occur when students are engaged in their own learning, including increased motivation and achievement. Previous studies have proposed many scales for measuring student engagement. However, very few have been developed to measure engagement in e-learning environments. Thus, developing an instrument for measuring student engagement in e-learning environments is the purpose of this study. The participants of this study were 737 Korean online university students. Initial items were designed based on the literature. The instrument items were reduced from an initial 48 to 24 items after obtaining expert opinion and then validity and reliability analysis. Exploratory and confirmatory factor analyses were also conducted. Six factors, including psychological motivation, peer collaboration, cognitive problem solving, interaction with instructors, community support, and learning management emerged in the 24-item scale. This scale is expected to help instructors and curriculum designers to find conditions to improve student engagement in e-learning environments, and ultimately prevent students from dropping out of online courses.},
DOI = {10.3390/su11040985}
}

@article{means2010,
author = {Means, Barbara and Toyama, Yukie and Murphy, Robert and Bakia, Marianne and Jones, Karla and Planning, Evaluation},
year = {2010},
month = {01},
pages = {},
title = {Evaluation of Evidence-Based Practices in Online Learning: A Meta-Analysis and Review of Online Learning Studies},
volume = {115},
journal = {http://lst-iiep.iiep-unesco.org/cgi-bin/wwwi32.exe/[in=epidoc1.in]/?t2000=027003/(100)}
}

@article{xiu2020,
author = {Ying, Xiu and Thompson, Penny},
year = {2020},
month = {01},
pages = {041-063},
title = {Flipped University Class: A Study of Motivation and Learning},
volume = {19},
journal = {Journal of Information Technology Education: Research},
doi = {10.28945/4500}
}

@article{shi2020,
author = {Shi, Yinghui and Ma, Yanqiong and MacLeod, Jason and Yang, Harrison Hao},
year = {2019},
month = {05},
pages = {},
title = {College students’ cognitive learning outcomes in flipped classroom instruction: a meta-analysis of the empirical literature},
volume = {7},
journal = {Journal of Computers in Education},
doi = {10.1007/s40692-019-00142-8}
}

@article{skilling2020,
author = {Skilling, Karen and Bobis, Janette and Martin, Andrew},
year = {2020},
month = {02},
pages = {1-25},
title = {The “ins and outs” of student engagement in mathematics: shifts in engagement factors among high and low achievers},
volume = {33},
journal = {Mathematics Education Research Journal},
doi = {10.1007/s13394-020-00313-2}
}

@article{maroco2016,
author = {Maroco, João and Maroco, Ana and Campos, Juliana and Fredricks, Jennifer},
year = {2016},
month = {12},
pages = {},
title = {University student's engagement: Development of the University Student Engagement Inventory (USEI)},
volume = {29},
journal = {Psicologia: Reflexão e Crítica},
doi = {10.1186/s41155-016-0042-8}
}

@article{assuncao2020,
author = {Assunção, Hugo and Lin, Su-Wei and Sit, Pou Seong and Cheung, Kwok-cheung and Harju-Luukkainen, Heidi and Smith, Thomas and Maloa, Benvindo and Campos, Juliana and Stepanovic Ilic, Ivana and Esposito, Giovanna and Freda, Maria and Maroco, João},
year = {2020},
month = {01},
pages = {1-12},
title = {University Student Engagement Inventory (USEI): Transcultural Validity Evidence Across Four Continents},
volume = {10},
journal = {Frontiers in Psychology},
doi = {10.3389/fpsyg.2019.02796}
}

@article{jose2022,
author = {Tomás, José and Gutiérrez, Melchor and Alberola, Salvador and Georgieva, Sylvia},
year = {2022},
month = {05},
pages = {},
title = {Psychometric properties of two major approaches to measure school engagement in university students},
volume = {41},
journal = {Current Psychology},
doi = {10.1007/s12144-020-00769-2}
}

@article{wong2022,
author = {Wong, Zi and Liem, Gregory Arief},
year = {2022},
month = {03},
pages = {1-32},
title = {Student Engagement: Current State of the Construct, Conceptual Refinement, and Future Research Directions},
volume = {34},
journal = {Educational Psychology Review},
doi = {10.1007/s10648-021-09628-3}
}

@article{morris2020,
author = {Thomas Howard Morris},
title = {Experiential learning – a systematic review and revision of Kolb’s model},
journal = {Interactive Learning Environments},
volume = {28},
number = {8},
pages = {1064-1077},
year  = {2020},
publisher = {Routledge},
doi = {10.1080/10494820.2019.1570279},
URL = { https://doi.org/10.1080/10494820.2019.1570279},
eprint = {https://doi.org/10.1080/10494820.2019.1570279},
abstract = { Kolb’s experiential learning cycle is perhaps the most scholarly influential and cited model regarding experiential learning theory. However, a key issue in interpreting Kolb’s model concerns a lack of clarity regarding what constitutes a concrete experience, exactly. A systematic literature review was conducted in order to examine: what constitutes a concrete experience and what is the nature of treatment of a concrete experience in experiential learning? The analysis revealed five themes: learners are involved, active, participants; knowledge is situated in place and time; learners are exposed to novel experiences, which involves risk; learning demands inquiry to specific real-world problems; and critical reflection acts as a mediator of meaningful learning. Accordingly, a revision to Kolb’s model is proposed: experiential learning consists of contextually rich concrete experience, critical reflective observation, contextual-specific abstract conceptualization, and pragmatic active experimentation. Further empirical studies are required to test the model proposed. }
}

@article{Katsaris2021,
title={Adaptive e-learning systems through learning styles: A review of the literature},
volume={1},
url={https://www.syncsci.com/journal/AMLER/article/view/AMLER.2021.02.007},
DOI={10.25082/AMLER.2021.02.007},
number={2},
journal={Advances in Mobile Learning Educational Research},
author={Katsaris, Iraklis and Vidakis, Nikolas},
year={2021},
month={Oct.},
pages={124-145}
}

@article{lewis2018,
author = {James R. Lewis},
title = {The System Usability Scale: Past, Present, and Future},
journal = {International Journal of Human–Computer Interaction},
volume = {34},
number = {7},
pages = {577-590},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/10447318.2018.1455307},

URL = {

        https://doi.org/10.1080/10447318.2018.1455307},
eprint = {

        https://doi.org/10.1080/10447318.2018.1455307}
,abstract = { ABSTRACTThe System Usability Scale (SUS) is the most widely used standardized questionnaire for the assessment of perceived usability. This review of the SUS covers its early history from inception in the 1980s through recent research and its future prospects. From relatively inauspicious beginnings, when its originator described it as a “quick and dirty usability scale,” it has proven to be quick but not “dirty.” It is likely that the SUS will continue to be a popular measurement of perceived usability for the foreseeable future. When researchers and practitioners need a measure of perceived usability, they should strongly consider using the SUS. }
}

@article{khamparia2020,
author = {Khamparia, Aditya and Pandey, Babita},
year = {2020},
month = {03},
pages = {1-29},
title = {Association of learning styles with different e-learning problems: a systematic review and classification},
volume = {25},
journal = {Education and Information Technologies},
doi = {10.1007/s10639-019-10028-y}
}

@article{bybee2006,
author = {Bybee, Rodger and Taylor, Joseph and Gardner, April and Scotter, Pamela and Carlson, Janet and Westbrook, Anne and Landes, Nancy},
year = {2006},
month = {01},
pages = {},
title = {The BSCS 5E Instructional Model: Origins, Effectiveness, and Applications},
journal = {BSCS}
}

@article{demmese2020,
title = {Evaluating the Effectiveness of Gamification on Students’ Performance in a Cybersecurity Course},
url = {https://par.nsf.gov/biblio/10290874},
abstractNote = {The motivation of students to actively engage in course activities has significant impact on the outcome of academic courses. Prior studies have shown that innovative instructional interventions and course delivery methods have a vital role in boosting the motivation of students. Gamification tools aid course delivery by utilizing well established game design principles to enhance skill development, routine practice and self-testing. In this article, we present a study on how the use of a course gamification platform dubbed OneUp impacts the motivation of students in an online cyber security course. The study shows that more than 90% of the respondents agreed that OneUp has improved the effectiveness of the course delivery. In addition, 75% of the respondents want to use OneUp in their future courses. Furthermore, our analysis shows that OneUp has improved the median grade of students from B+ to A- compared to the same course delivered the previous year without using OneUp.},
journal = {Journal of the Colloquium for Information System Security Education},
volume = {8},
number = {1},
author = {Demmese, F. and Yuan, X. and Dicheva, D.},
}

@article{susnjak2022,
author = {Susnjak, Teo and Ramaswami, Gomathy and Mathrani, Anuradha},
year = {2022},
month = {02},
pages = {12},
title = {Learning analytics dashboard: a tool for providing actionable insights to learners},
volume = {19},
journal = {International Journal of Educational Technology in Higher Education},
doi = {10.1186/s41239-021-00313-7}
}

@article{duran2004,
  title={The 5E instructional model: A learning cycle approach for inquiry-based science teaching.},
  author={Duran, Lena Ballone and Duran, Emilio},
  journal={Science Education Review},
  volume={3},
  number={2},
  pages={49--58},
  year={2004},
  publisher={ERIC}
}

@article{eisenkraft2003,
  title={Expanding the 5E Model.},
  author={Eisenkraft, Arthur},
  journal={Science Teacher},
  volume={70},
  number={6},
  pages={56--59},
  year={2003},
  publisher={ERIC}
}

@article{su2010,
author = {Su, C.Y. and Chiu, C.H. and Wang, T.I.},
title = {The development of SCORM-conformant learning content based on the learning cycle using participatory design},
journal = {Journal of Computer Assisted Learning},
volume = {26},
number = {5},
pages = {392-406},
keywords = {e-learning materials, elementary science learning, participatory design, 5E learning cycle},
doi = {https://doi.org/10.1111/j.1365-2729.2010.00355.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2729.2010.00355.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2729.2010.00355.x},
abstract = {Abstract This study incorporates the 5E learning cycle strategy to design and develop Sharable Content Object Reference Model-conformant materials for elementary science education. The 5E learning cycle that supports the constructivist approach has been widely applied in science education. The strategy consists of five phases: engagement, exploration, explanation, elaboration and evaluation. It has potential value for creating effective science e-learning materials. This study implemented the participatory design (PD) method to investigate the possibility of applying the 5E model to science e-learning materials. PD is an approach that understands knowledge by doing and focuses on collaborating with the intended users rather than designing ‘for’ them. In this study, researchers, designers and elementary science teachers cooperated at all stages of the design process (including explanation, analysis and decision making). The issues to be dealt with in this study included instructional designs based on the 5E model, techniques or specifications of e-learning, learning objects, metadata and procedures. The results of this study provided concrete recommendations for how to incorporate the 5E learning cycle and how to develop effective e-learning materials for elementary science instruction.},
year = {2010}
}

@article{meylani2015,
author = {Meylani, Rusen and Bitter, Gary and Legacy, Jane},
year = {2015},
month = {01},
pages = {},
title = {Desirable Characteristics of an Ideal Online Learning Environment},
journal = {Journal of Educational and Social Research},
doi = {10.5901/jesr.2015.v5n1p203}
}

@article{OZYURT2015,
title = {Learning style based individualized adaptive e-learning environments: Content analysis of the articles published from 2005 to 2014},
journal = {Computers in Human Behavior},
volume = {52},
pages = {349-358},
year = {2015},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2015.06.020},
url = {https://www.sciencedirect.com/science/article/pii/S0747563215004604},
author = {Özcan Özyurt and Hacer Özyurt},
keywords = {Adaptive educational hypermedia, Individualized e-learning, Learning style, Content analysis},
abstract = {The studies on creating learning environments based on differences in learning styles have gained importance in recent years. Learning styles are one of the most important parameters in determining individual differences. Accordingly, traditional web-based learning environments have been replaced by individualized adaptive e-learning environments on the basis of learning styles which are more innovative. This study deals with the content analysis of the recent studies on Adaptive Educational Hypermedia (AEH) based on learning styles. 69 articles published from 2005 to 2014 were obtained through a comprehensive and detailed review. Afterwards, these studies were subjected to document analysis. The studies were categorized under the titles of purpose, nature, method, characteristics of examinees, level, data collection tool, learner modelling, learning styles, subject, and findings. Some of the studies offered a framework or proposed a model for AEH while others focused on the influence of AEH on academic achievement and learning outputs as well as learning satisfaction. This study examines the existing tendencies and gaps in the literature and discusses the potential research topics.}
}

@article{el-sabagh2021,
author = {El-Sabagh, Hassan},
year = {2021},
month = {10},
pages = {1-24},
title = {Adaptive e-learning environment based on learning styles and its impact on development students' engagement},
volume = {18},
doi = {10.1186/s41239-021-00289-4}
}

@article{kolekar2019,
author = {Kolekar, Sucheta and Pai, Radhika and M M, Manohara},
year = {2019},
month = {01},
pages = {},
title = {Rule based adaptive user interface for adaptive E-learning system},
volume = {24},
journal = {Education and Information Technologies},
doi = {10.1007/s10639-018-9788-1}
}
@article{gurcan2021,
  title="Investigation of Emerging Trends in the E-Learning Field Using Latent Dirichlet Allocation",
  author="Gurcan, Fatih ; Ozyurt, Ozcan ; Cagitay, Nergiz Ercil",
  journal="International Review of Research in Open and Distributed Learning",
  volume="22",
  number="2",
  pages="1--18",
  year="2021",
  publisher="Athabasca University Press (AU Press)",
  doi="https://doi.org/10.19173/irrodl.v22i2.5358"
}

@article{eshima2023,
author = {Eshima, Shusei and Imai, Kosuke and Sasaki, Tomoya},
title = {Keyword-Assisted Topic Models},
journal = {American Journal of Political Science},
year={2023},
volume = {n/a},
number = {n/a},
pages = {},
doi = {https://doi.org/10.1111/ajps.12779},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12779},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ajps.12779},
abstract = {Abstract In recent years, fully automated content analysis based on probabilistic topic models has become popular among social scientists because of their scalability. However, researchers find that these models often fail to measure specific concepts of substantive interest by inadvertently creating multiple topics with similar content and combining distinct themes into a single topic. In this article, we empirically demonstrate that providing a small number of keywords can substantially enhance the measurement performance of topic models. An important advantage of the proposed keyword-assisted topic model (keyATM) is that the specification of keywords requires researchers to label topics prior to fitting a model to the data. This contrasts with a widespread practice of post hoc topic interpretation and adjustments that compromises the objectivity of empirical findings. In our application, we find that keyATM provides more interpretable results, has better document classification performance, and is less sensitive to the number of topics.}
}

@article{fatahi2019,
author = {Fatahi, Somayeh},
year = {2019},
month = {07},
pages = {},
title = {An experimental study on an adaptive e-learning environment based on learner’s personality and emotion},
volume = {24},
journal = {Education and Information Technologies},
doi = {10.1007/s10639-019-09868-5}
}































@ARTICLE{Lamon_et_al,

AUTHOR={Lamon, Séverine and Knowles, Olivia and Hendy, Ashlee and Story, Ian and Currey, Judy},

TITLE={Active Learning to Improve Student Learning Experiences in an Online Postgraduate Course},

JOURNAL={Frontiers in Education},

VOLUME={5},

YEAR={2020},

URL={https://www.frontiersin.org/articles/10.3389/feduc.2020.598560},

DOI={10.3389/feduc.2020.598560},

ISSN={2504-284X},

ABSTRACT={Post-graduate programs attract older students, who often work part-time or full-time and have child-care responsibilities. In the Information Age, online learning environments can help these students to meet their learning objectives more efficiently and provide a unique opportunity to address individual learning preferences. The aim of this study was to assess the learning experiences of postgraduate students in an online learning environment delivering content in a guided, self-directed way focusing on active learning opportunities. Two-hundred and eighty-seven students participated in the study. A pragmatic descriptive design with purposive sampling was used to examine the impact of a newly developed active online learning environment on student commitment, performance and satisfaction when compared to a passive, pre-recorded lecture. In contrast to our hypothesis that all metrics would improve with subject redevelopment, student performance and commitment did not improve in the active online learning environment; however, student satisfaction increased significantly. These findings might be partly attributed to the increased cognitive load associated to online learning. This study demonstrates how, for postgraduate students choosing online learning, active learning experiences can be used to provide students with a greater sense of satisfaction while acknowledging for the heterogeneity of the cohort and its different learning preferences. However, in the worldwide context of remote learning rapidly and urgently expanding, it also outlines that online learning needs to be carefully scaffolded to ensure deep learning and that the impact of the transition to online learning on performance and commitment should be considered, especially when directed at non-experienced students.}
}

@article{Molenaar_et_al,
author = {Molenaar, Inge and Horvers, Anne and Dijkstra, Rick and Baker, Ryan},
year = {2019},
month = {02},
pages = {},
title = {Designing Dashboards to support learners' Self-Regulated Learning}
}

@article{SEDRAKYAN2020105512,
title = {Linking learning behavior analytics and learning science concepts: Designing a learning analytics dashboard for feedback to support learning regulation},
journal = {Computers in Human Behavior},
volume = {107},
pages = {105512},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218302309},
author = {Gayane Sedrakyan and Jonna Malmberg and Katrien Verbert and Sanna Järvelä and Paul A. Kirschner},
keywords = {Learning analytics dashboards, Learning process analytics, Behavior analytics, Regulation of learning, Process-oriented feedback, Feedback automation},
abstract = {Technological advancements have generated a strong interest in exploring learner behavior data through learning analytics to provide both learner and instructor with process-oriented feedback in the form of dashboards. However, little is known about the typology of dashboard feedback relevant for different learning goals, learners and teachers. While most dashboards and the feedback that they give are based only on learner performance indicators, research shows that effective feedback needs also to be grounded in the regulatory mechanisms underlying learning processes and an awareness of the learner's learning goals. The design artefact presented in this article uses a conceptual model that visualizes the relationships between dashboard design and the learning sciences to provide cognitive and behavioral process-oriented feedback to learners and teachers to support regulation of learning. A practical case example is given that demonstrates how the ideas presented in the paper can be deployed in the context of a learning dashboard. The case example uses several analytics/visualization techniques based on empirical evidence from earlier research that successfully tested these techniques in various learning contexts.}
}

@article{Rajanen,
author = {Rajanen (Marghescu), Dorina and Rajanen, Mikko},
year = {2022},
month = {07},
pages = {5441-5450},
title = {STUDENT-CENTRED DESIGN OF LEARNING DASHBOARDS},
doi = {10.21125/edulearn.2022.1288}
}



@article{Yousaf,
author = {Hummaira Qudsia Yousaf and Sumaira Rehman and Muneeb Ahmed and Sidra Munawar},
title = {Investigating students’ satisfaction in online learning: the role of students’ interaction and engagement in universities},
journal = {Interactive Learning Environments},
volume = {0},
number = {0},
pages = {1-18`},
year  = {2022},
publisher = {Routledge},
doi = {10.1080/10494820.2022.2061009},

URL = {

        https://doi.org/10.1080/10494820.2022.2061009



},
eprint = {https://doi.org/10.1080/10494820.2022.2061009}}


@ARTICLE{Xing2022,

AUTHOR={Li, Xing and Lin, Xinyue and Zhang, Fan and Tian, Yuan},

TITLE={What Matters in Online Education: Exploring the Impacts of Instructional Interactions on Learning Outcomes},

JOURNAL={Frontiers in Psychology},

VOLUME={12},

YEAR={2022},

URL={https://www.frontiersin.org/articles/10.3389/fpsyg.2021.792464},

DOI={10.3389/fpsyg.2021.792464},

ISSN={1664-1078},
}

@Article{Muir2022,
AUTHOR = {Muir, Tracey and Wang, Isabel and Trimble, Allison and Mainsbridge, Casey and Douglas, Tracy},
TITLE = {Using Interactive Online Pedagogical Approaches to Promote Student Engagement},
JOURNAL = {Education Sciences},
VOLUME = {12},
YEAR = {2022},
NUMBER = {6},
ARTICLE-NUMBER = {415},
URL = {https://www.mdpi.com/2227-7102/12/6/415},
ISSN = {2227-7102},
DOI = {10.3390/educsci12060415}}

@article{Doi2022,
author = {Doi, Jimmy and Potter, Gail and WONG, JIMMY and ALCARAZ, IRVIN and CHI, PETER},
year = {2016},
month = {01},
pages = {},
title = {Web Application Teaching Tools for Statistics Using R and Shiny},
volume = {9},
journal = {Technology Innovations in Statistics Education},
doi = {10.5070/T591027492}}


@article{Wang2021,
author = {Sabrina Luxin Wang and Anna Yinqi Zhang and Samuel Messer and Andrew Wiesner and Dennis K. Pearl},
title = {Student-Developed Shiny Applications for Teaching Statistics},
journal = {Journal of Statistics and Data Science Education},
volume = {29},
number = {3},
pages = {218-227},
year  = {2021},
publisher = {Taylor & Francis},
doi = {10.1080/26939169.2021.1995545},

URL = {https://doi.org/10.1080/26939169.2021.1995545},
eprint = {https://doi.org/10.1080/26939169.2021.1995545}}


@article{Wang2023,
author = {Wang, Han and Huang, Tao and Zhao, Yuan and Hu, Shengze},
year = {2023},
month = {03},
pages = {4474},
title = {The Impact of Dashboard Feedback Type on Learning Effectiveness, Focusing on Learner Differences},
volume = {15},
journal = {Sustainability},
doi = {10.3390/su15054474}
}


@article{Park2019,
author = {Park, Yeonjeong and Jo, Il-Hyun},
year = {2019},
month = {07},
pages = {},
title = {Factors that affect the success of learning analytics dashboards},
volume = {67},
journal = {Educational Technology Research and Development},
doi = {10.1007/s11423-019-09693-0}
}

@article{AKCAPINAR2022,
title = {Discovering the effects of learning analytics dashboard on students’ behavioral patterns using differential sequence mining},
journal = {Procedia Computer Science},
volume = {207},
pages = {3818-3825},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.443},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922013369},
author = {Gökhan Akçapınar and Mohammad Nehal Hasnine},
keywords = {Learning analytics, intervention, dashboard, temporal learning analytics, differential sequence mining},
}

@article{DeQuincey2019,
author = {De Quincey, Ed and Briggs, Christopher and Kyriacou, Theocharis and Waller, Richard},
year = {2019},
month = {03},
pages = {353-362},
title = {Student Centred Design of a Learning Analytics System},
doi = {10.1145/3303772.3303793}
}



@article{Fawcett2018,
author = {Lee Fawcett},
title = {Using Interactive Shiny Applications to Facilitate Research-Informed Learning and Teaching},
journal = {Journal of Statistics Education},
volume = {26},
number = {1},
pages = {2-16},
year  = {2018},
publisher = {Taylor & Francis},
doi = {10.1080/10691898.2018.1436999},
URL = {https://doi.org/10.1080/10691898.2018.1436999},eprint = {https://doi.org/10.1080/10691898.2018.1436999}}


@article{Moore2022,
author = {Moore, Tadhg and Thomas, Quinn and Woelmer, Whitney and Carey, Cayelan},
year = {2022},
month = {06},
pages = {604-633},
title = {Integrating Ecological Forecasting into Undergraduate Ecology Curricula with an R Shiny Application-Based Teaching Module},
volume = {4},
journal = {Forecasting},
doi = {10.3390/forecast4030033}
}

@article{Neyhart2020,
author = {Neyhart, Jeffrey L. and Watkins, Eric},
title = {An active learning tool for quantitative genetics instruction using R and shiny},
journal = {Natural Sciences Education},
volume = {49},
number = {1},
pages = {e20026},
doi = {https://doi.org/10.1002/nse2.20026},
url = {https://acsess.onlinelibrary.wiley.com/doi/abs/10.1002/nse2.20026},
eprint = {https://acsess.onlinelibrary.wiley.com/doi/pdf/10.1002/nse2.20026},
year = {2020}
}

@article{Auker2020,
author = {Auker, Linda A. and Barthelmess, Erika L.},
title = {Teaching R in the undergraduate ecology classroom: approaches, lessons learned, and recommendations},
journal = {Ecosphere},
volume = {11},
number = {4},
pages = {e03060},
keywords = {data analysis, data management, pedagogy, R, repeatability, statistics, teaching},
doi = {https://doi.org/10.1002/ecs2.3060},
url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecs2.3060},
eprint = {https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ecs2.3060},
year = {2020}
}

@article{Johnson2022,
    doi = {10.1371/journal.pone.0262145},
    author = {Johnson, Olatunji AND Fronterre, Claudio AND Diggle, Peter J. AND Amoah, Benjamin AND Giorgi, Emanuele},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {MBGapp: A Shiny application for teaching model-based geostatistics to population health scientists},
    year = {2022},
    month = {12},
    volume = {16},
    url = {https://doi.org/10.1371/journal.pone.0262145},
    pages = {1-12},
    abstract = {User-friendly interfaces have been increasingly used to facilitate the learning of advanced statistical methodology, especially for students with only minimal statistical training. In this paper, we illustrate the use of MBGapp for teaching geostatistical analysis to population health scientists. Using a case-study on Loa loa infections, we show how MBGapp can be used to teach the different stages of a geostatistical analysis in a more interactive fashion. For wider accessibility and usability, MBGapp is available as an R package and as a Shiny web-application that can be freely accessed on any web browser. In addition to MBGapp, we also present an auxiliary Shiny app, called VariagramApp, that can be used to aid the teaching of Gaussian processes in one and two dimensions using simulations.},
    number = {12},

}

@article{Zhang,
author = {Zhang, Shirong and de Koning, Bjorn B. and Paas, Fred},
title = {Effects of finger and mouse pointing on learning from online split-attention examples},
journal = {British Journal of Educational Psychology},
volume = {n/a},
number = {n/a},
pages = {},
keywords = {Cognitive load theory, learning, pointing, self-management, split-attention effect},
doi = {https://doi.org/10.1111/bjep.12556},
url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/bjep.12556},
eprint = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/bjep.12556},
}
